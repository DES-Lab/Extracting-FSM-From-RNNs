{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd02ab5e152fcf54322d6bbdd14ee60841ff95c5546cc9d5585d8c09cbd67c517cd",
   "display_name": "Python 3.6.8 64-bit ('venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from aalpy.SULs import MealySUL\n",
    "from aalpy.oracles import StatePrefixEqOracle\n",
    "\n",
    "from Applications import label_sequences_with_correct_model\n",
    "from DataProcessing import get_coffee_machine, generate_data_from_automaton, split_train_validation, tokenize\n",
    "from RNNClassifier import RNNClassifier\n",
    "from TrainAndExtract import extract_finite_state_transducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coffee machine FSM used for data generation\n",
    "ground_truth_model = get_coffee_machine()\n",
    "\n",
    "# Get input and output alphabet \n",
    "input_al = ground_truth_model.get_input_alphabet()\n",
    "output_al = {output for state in ground_truth_model.states for output in state.output_fun.values()}\n",
    "\n",
    "# Create the small initial training set\n",
    "train_seq, train_labels = generate_data_from_automaton(ground_truth_model, input_al,\n",
    "                                                       num_examples=1000, lens=(3, 6, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a number of RNNs that will be used for learning-based testing\n",
    "# Each NN will be trained with the training data set.\n",
    "# Models will be mined from all RNNs and cross checked for conformance.\n",
    "# Cases of non-conformance are added to the training set.\n",
    "NUM_RNNs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning/extraction round: 1\n",
      "Starting training of RNN 0\n",
      "Starting training of RNN 1\n",
      "Starting training of RNN 2\n",
      "Starting training of RNN 3\n",
      "Starting extraction of the automaton from RNN 0\n",
      "Starting extraction of the automaton from RNN 1\n",
      "Starting extraction of the automaton from RNN 2\n",
      "Starting extraction of the automaton from RNN 3\n",
      "Adding 86 new examples to training data.\n",
      "Size of training data: 1088\n",
      "Learning/extraction round: 2\n",
      "Starting training of RNN 0\n",
      "Starting training of RNN 1\n",
      "Starting training of RNN 2\n",
      "Starting training of RNN 3\n",
      "Starting extraction of the automaton from RNN 0\n",
      "Starting extraction of the automaton from RNN 1\n",
      "Starting extraction of the automaton from RNN 2\n",
      "Starting extraction of the automaton from RNN 3\n",
      "Adding 52 new examples to training data.\n",
      "Size of training data: 1140\n",
      "Learning/extraction round: 3\n",
      "Starting training of RNN 0\n",
      "Starting training of RNN 1\n",
      "Starting training of RNN 2\n",
      "Starting training of RNN 3\n",
      "Starting extraction of the automaton from RNN 0\n",
      "Starting extraction of the automaton from RNN 1\n",
      "Starting extraction of the automaton from RNN 2\n",
      "Starting extraction of the automaton from RNN 3\n",
      "Adding 88 new examples to training data.\n",
      "Size of training data: 1228\n",
      "Learning/extraction round: 4\n",
      "Starting training of RNN 0\n",
      "Starting training of RNN 1\n",
      "Starting training of RNN 2\n",
      "Starting training of RNN 3\n",
      "Starting extraction of the automaton from RNN 0\n",
      "Starting extraction of the automaton from RNN 1\n",
      "Starting extraction of the automaton from RNN 2\n",
      "Starting extraction of the automaton from RNN 3\n",
      "Adding 88 new examples to training data.\n",
      "Size of training data: 1316\n",
      "Learning/extraction round: 5\n",
      "Starting training of RNN 0\n",
      "Starting training of RNN 1\n",
      "Starting training of RNN 2\n",
      "Starting training of RNN 3\n",
      "Starting extraction of the automaton from RNN 0\n",
      "Starting extraction of the automaton from RNN 1\n",
      "Starting extraction of the automaton from RNN 2\n",
      "Starting extraction of the automaton from RNN 3\n",
      "Adding 62 new examples to training data.\n",
      "Size of training data: 1378\n",
      "Learning/extraction round: 6\n",
      "Starting training of RNN 0\n",
      "Starting training of RNN 1\n",
      "Starting training of RNN 2\n",
      "Starting training of RNN 3\n",
      "Starting extraction of the automaton from RNN 0\n",
      "Starting extraction of the automaton from RNN 1\n",
      "Starting extraction of the automaton from RNN 2\n",
      "Starting extraction of the automaton from RNN 3\n",
      "Size of automata 0: 24\n",
      "Size of automata 1: 12\n",
      "Size of automata 2: 12\n",
      "Size of automata 3: 9\n",
      "digraph learnedModel {\n",
      "s0 [label=s0];\n",
      "s1 [label=s1];\n",
      "s2 [label=s2];\n",
      "s3 [label=s3];\n",
      "s4 [label=s4];\n",
      "s5 [label=s5];\n",
      "s6 [label=s6];\n",
      "s7 [label=s7];\n",
      "s8 [label=s8];\n",
      "s0 -> s0  [label=\"clean/check\"];\n",
      "s0 -> s2  [label=\"pod/check\"];\n",
      "s0 -> s7  [label=\"water/check\"];\n",
      "s0 -> s1  [label=\"button/star\"];\n",
      "s1 -> s5  [label=\"clean/star\"];\n",
      "s1 -> s1  [label=\"pod/star\"];\n",
      "s1 -> s1  [label=\"water/star\"];\n",
      "s1 -> s1  [label=\"button/star\"];\n",
      "s2 -> s0  [label=\"clean/check\"];\n",
      "s2 -> s2  [label=\"pod/check\"];\n",
      "s2 -> s3  [label=\"water/check\"];\n",
      "s2 -> s1  [label=\"button/star\"];\n",
      "s3 -> s0  [label=\"clean/check\"];\n",
      "s3 -> s3  [label=\"pod/check\"];\n",
      "s3 -> s3  [label=\"water/check\"];\n",
      "s3 -> s4  [label=\"button/coffee\"];\n",
      "s4 -> s0  [label=\"clean/check\"];\n",
      "s4 -> s1  [label=\"pod/coffee\"];\n",
      "s4 -> s1  [label=\"water/coffee\"];\n",
      "s4 -> s1  [label=\"button/coffee\"];\n",
      "s5 -> s5  [label=\"clean/star\"];\n",
      "s5 -> s5  [label=\"pod/star\"];\n",
      "s5 -> s6  [label=\"water/star\"];\n",
      "s5 -> s1  [label=\"button/star\"];\n",
      "s6 -> s5  [label=\"clean/star\"];\n",
      "s6 -> s8  [label=\"pod/star\"];\n",
      "s6 -> s6  [label=\"water/star\"];\n",
      "s6 -> s1  [label=\"button/star\"];\n",
      "s7 -> s0  [label=\"clean/check\"];\n",
      "s7 -> s3  [label=\"pod/check\"];\n",
      "s7 -> s7  [label=\"water/check\"];\n",
      "s7 -> s1  [label=\"button/star\"];\n",
      "s8 -> s6  [label=\"clean/star\"];\n",
      "s8 -> s8  [label=\"pod/star\"];\n",
      "s8 -> s8  [label=\"water/star\"];\n",
      "s8 -> s1  [label=\"button/star\"];\n",
      "__start0 [label=\"\", shape=none];\n",
      "__start0 -> s0  [label=\"\"];\n",
      "}\n",
      "\n",
      "No counterexamples between extracted automata found.\n"
     ]
    }
   ],
   "source": [
    "# While the input-output behaviour of all trained neural networks is different\n",
    "iteration = 0\n",
    "while True:\n",
    "    iteration += 1\n",
    "    print(f'Learning/extraction round: {iteration}')\n",
    "\n",
    "    trained_networks = []\n",
    "\n",
    "    x_train, y_train, x_test, y_test = split_train_validation(train_seq, train_labels, 0.8, uniform=True)\n",
    "\n",
    "    # Train all neural networks with same parameters\n",
    "    for i in range(NUM_RNNs):\n",
    "        rnn = RNNClassifier(input_al, output_dim=len(output_al), num_layers=2, hidden_dim=40,\n",
    "                            x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test,\n",
    "                            batch_size=32, nn_type='GRU')\n",
    "        print(f'Starting training of RNN {i}')\n",
    "        rnn.train(epochs=150, stop_acc=1.0, stop_epochs=3, verbose=False)\n",
    "        trained_networks.append(rnn)\n",
    "\n",
    "    learned_automatons = []\n",
    "\n",
    "    # Extract automaton for each neural network\n",
    "    for i, rnn in enumerate(trained_networks):\n",
    "        print(f'Starting extraction of the automaton from RNN {i}')\n",
    "        learned_automaton = extract_finite_state_transducer(rnn, input_al, output_al, max_learning_rounds=6,\n",
    "                                                            print_level=0)\n",
    "        learned_automatons.append(learned_automaton)\n",
    "\n",
    "    learned_automatons.sort(key=lambda x: len(x.states), reverse=True)\n",
    "\n",
    "    # Select one automaton as a basis for conformance-checking. You can also do conformance checking with all pairs\n",
    "    # of learned automata.\n",
    "\n",
    "    base_sul = MealySUL(learned_automatons[0])\n",
    "\n",
    "    # Select the eq. oracle\n",
    "\n",
    "    eq_oracle = StatePrefixEqOracle(input_al, base_sul, walks_per_state=100, walk_len=50)\n",
    "\n",
    "    cex_set = set()\n",
    "\n",
    "    # Try to find cases of non-conformance between learned automatons.\n",
    "    for la in learned_automatons[1:]:\n",
    "        for i in range(200):\n",
    "            cex = eq_oracle.find_cex(la)\n",
    "            if cex:\n",
    "                cex_set.add(tuple(cex))\n",
    "\n",
    "    # If there were no counterexamples between any learned automata, we end the procedure\n",
    "    if not cex_set:\n",
    "        for i, la in enumerate(learned_automatons):\n",
    "            print(f'Size of automata {i}: {len(la.states)}')\n",
    "        print(learned_automatons[-1])\n",
    "        print('No counterexamples between extracted automata found.')\n",
    "        break\n",
    "\n",
    "    # Ask ground truth model for correct labels\n",
    "    new_x, new_y = label_sequences_with_correct_model(ground_truth_model, cex_set)\n",
    "\n",
    "    print(f'Adding {len(cex_set)} new examples to training data.')\n",
    "    new_x = tokenize(new_x, input_al)\n",
    "    new_y = tokenize(new_y, output_al)\n",
    "\n",
    "    train_seq.extend(new_x)\n",
    "    train_labels.extend(new_y)\n",
    "    print(f'Size of training data: {len(train_seq)}')"
   ]
  }
 ]
}