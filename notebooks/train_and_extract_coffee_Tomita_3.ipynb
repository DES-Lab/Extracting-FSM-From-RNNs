{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd02ab5e152fcf54322d6bbdd14ee60841ff95c5546cc9d5585d8c09cbd67c517cd",
   "display_name": "Python 3.6.8 64-bit ('venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from aalpy.learning_algs import run_Lstar\n",
    "from aalpy.oracles import StatePrefixEqOracle\n",
    "from aalpy.utils import save_automaton_to_file\n",
    "\n",
    "from RNN_SULs import RnnBinarySUL\n",
    "from TrainAndExtract import train_RNN_on_tomita_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting train\n",
      "Epoch 0: Accuracy 0.51596, Avg. Loss 12.49723 Validation Accuracy 0.52663\n",
      "Epoch 1: Accuracy 0.54226, Avg. Loss 12.35145 Validation Accuracy 0.5503\n",
      "Epoch 2: Accuracy 0.64096, Avg. Loss 11.92443 Validation Accuracy 0.6071\n",
      "Epoch 3: Accuracy 0.71483, Avg. Loss 11.0601 Validation Accuracy 0.70414\n",
      "Epoch 4: Accuracy 0.84427, Avg. Loss 8.7699 Validation Accuracy 0.83669\n",
      "Epoch 5: Accuracy 0.9409, Avg. Loss 4.33512 Validation Accuracy 0.93254\n",
      "Epoch 6: Accuracy 0.99025, Avg. Loss 1.76336 Validation Accuracy 0.98462\n",
      "Epoch 7: Accuracy 0.99941, Avg. Loss 0.33405 Validation Accuracy 1.0\n",
      "Epoch 8: Accuracy 1.0, Avg. Loss 0.06027 Validation Accuracy 1.0\n",
      "Epoch 9: Accuracy 1.0, Avg. Loss 0.02952 Validation Accuracy 1.0\n",
      "Epoch 10: Accuracy 1.0, Avg. Loss 0.0194 Validation Accuracy 1.0\n",
      "Done training!\n"
     ]
    }
   ],
   "source": [
    "# Learn and extract tomita 3 grammar.\n",
    "rnn = train_RNN_on_tomita_grammar(tomita_grammar=3, acc_stop=1., loss_stop=0.005, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomita grammars have binary alphabet.\n",
    "tomita_alphabet = [\"0\", \"1\"]\n",
    "\n",
    "# Wrap RNN in SUL class\n",
    "sul = RnnBinarySUL(rnn)\n",
    "\n",
    "# Define coverage-based equivalence oracle\n",
    "# Note that walk_len is relatively short, so that extracted model that conforms to the Tomita 3 grammar.\n",
    "# (and does not find further adversarial inputs that would make the model bigger)\n",
    "# If you want to see how adversarial inputs can be found, use walks_per_state=500, walk_len=25 configuration\n",
    "state_eq_oracle = StatePrefixEqOracle(tomita_alphabet, sul, walks_per_state=200, walk_len=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hypothesis 1: 1 states.\n",
      "---------------------\n",
      "Prefixes / E set |() \n",
      "---------------------\n",
      "()               |1  \n",
      "=====================\n",
      "---------------------\n",
      "('0',)           |1  \n",
      "---------------------\n",
      "('1',)           |1  \n",
      "---------------------\n",
      "Counterexample ('0', '1', '0')\n",
      "Hypothesis 2: 4 states.\n",
      "---------------------------------\n",
      "Prefixes / E set     |() |('0',) \n",
      "---------------------------------\n",
      "()                   |1  |1      \n",
      "---------------------------------\n",
      "('1',)               |1  |0      \n",
      "---------------------------------\n",
      "('1', '0')           |0  |1      \n",
      "---------------------------------\n",
      "('1', '0', '1')      |0  |0      \n",
      "=================================\n",
      "---------------------------------\n",
      "('0',)               |1  |1      \n",
      "---------------------------------\n",
      "('1', '1')           |1  |1      \n",
      "---------------------------------\n",
      "('1', '0', '0')      |1  |0      \n",
      "---------------------------------\n",
      "('1', '0', '1', '0') |0  |0      \n",
      "---------------------------------\n",
      "('1', '0', '1', '1') |0  |0      \n",
      "---------------------------------\n",
      "Counterexample ('1', '0', '0', '1', '0')\n",
      "Hypothesis 3: 5 states.\n",
      "---------------------------------------------\n",
      "Prefixes / E set     |() |('0',) |('1', '0') \n",
      "---------------------------------------------\n",
      "()                   |1  |1      |0          \n",
      "---------------------------------------------\n",
      "('1',)               |1  |0      |1          \n",
      "---------------------------------------------\n",
      "('1', '0')           |0  |1      |0          \n",
      "---------------------------------------------\n",
      "('1', '0', '1')      |0  |0      |0          \n",
      "---------------------------------------------\n",
      "('1', '0', '0')      |1  |0      |0          \n",
      "=============================================\n",
      "---------------------------------------------\n",
      "('0',)               |1  |1      |0          \n",
      "---------------------------------------------\n",
      "('1', '1')           |1  |1      |0          \n",
      "---------------------------------------------\n",
      "('1', '0', '1', '0') |0  |0      |0          \n",
      "---------------------------------------------\n",
      "('1', '0', '1', '1') |0  |0      |0          \n",
      "---------------------------------------------\n",
      "('1', '0', '0', '0') |0  |1      |0          \n",
      "---------------------------------------------\n",
      "('1', '0', '0', '1') |1  |0      |0          \n",
      "---------------------------------------------\n",
      "-----------------------------------\n",
      "Learning Finished.\n",
      "Learning Rounds:  3\n",
      "Number of states: 5\n",
      "Time (in seconds)\n",
      "  Total                : 0.92\n",
      "  Learning algorithm   : 0.01\n",
      "  Conformance checking : 0.91\n",
      "Learning Algorithm\n",
      " # Membership Queries  : 13\n",
      " # MQ Saved by Caching : 24\n",
      " # Steps               : 41\n",
      "Equivalence Query\n",
      " # Membership Queries  : 1000\n",
      " # Steps               : 7795\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "learned_model = run_Lstar(alphabet=tomita_alphabet, sul=sul, eq_oracle=state_eq_oracle, automaton_type='dfa',\n",
    "                          cache_and_non_det_check=True, max_learning_rounds=10, print_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "digraph learnedModel {\ns0 [label=s0, shape=doublecircle];\ns1 [label=s1, shape=doublecircle];\ns2 [label=s2];\ns3 [label=s3];\ns4 [label=s4, shape=doublecircle];\ns0 -> s0  [label=0];\ns0 -> s1  [label=1];\ns1 -> s2  [label=0];\ns1 -> s0  [label=1];\ns2 -> s4  [label=0];\ns2 -> s3  [label=1];\ns3 -> s3  [label=0];\ns3 -> s3  [label=1];\ns4 -> s2  [label=0];\ns4 -> s4  [label=1];\n__start0 [label=\"\", shape=none];\n__start0 -> s0  [label=\"\"];\n}\n\n"
     ]
    }
   ],
   "source": [
    "# Save to file\n",
    "# save_automaton_to_file(learned_model, f'RNN_Models/tomita{3}')\n",
    "\n",
    "# Print extracted model\n",
    "print(learned_model)"
   ]
  }
 ]
}